{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2094b8",
   "metadata": {},
   "source": [
    "# Feedback Prize Effectiveness: Model Training and Validation (Longformer + GroupKFold + AMP + GradAccum)\n",
    "\n",
    "This notebook covers the complete pipeline for training and validating a Longformer model to predict the effectiveness of discourse elements in student essays. Key changes from the previous version include:\n",
    "1. **Model**: Using `allenai/longformer-base-4096` with `MAX_LEN = 1024`.\n",
    "2. **Input Formulation**: Discourse elements are surrounded by context from the essay: `[CLS] type [SEP] text [SEP] context_before [SEP] context_after [SEP]`.\n",
    "3. **Validation Strategy**: Using `GroupKFold` cross-validation, grouping by `essay_id`.\n",
    "4. **Performance**: Implemented Automatic Mixed Precision (AMP) and Gradient Accumulation (2 steps) for potentially faster training and larger effective batch size.\n",
    "5. **Setup and Configuration**: Importing necessary libraries and defining constants.\n",
    "6. **Data Loading and Preprocessing**: Loading training data and essay texts.\n",
    "7. **Target Encoding**: Converting categorical labels to numerical format.\n",
    "8. **Tokenizer Initialization**: Setting up `LongformerTokenizerFast`.\n",
    "9. **PyTorch Dataset and DataLoader Creation**: Defining custom Dataset and DataLoaders.\n",
    "10. **Model Definition**: Loading `LongformerForSequenceClassification`.\n",
    "11. **Optimizer, Scheduler, and Loss Function**: Configuring these for each fold.\n",
    "12. **Training and Evaluation Loop**: Main loop for K-fold training and evaluation with AMP and gradient accumulation.\n",
    "13. **Saving Best Models**: Storing model (config, weights) and tokenizer for each fold using `save_pretrained`.\n",
    "14. **Reporting**: Averaging metrics across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9305740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "AMP is enabled for CUDA training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdenis-katkalo\u001b[0m (\u001b[33mdenis-katkalo-kpi\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../outputs/wandb/run-20250521_190231-7r12h0mo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab/runs/7r12h0mo' target=\"_blank\">longformer-base-4096-len1024-e3pf-lr1e-05-eff_bs8-5f-20250521-1902</a></strong> to <a href='https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab' target=\"_blank\">https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab/runs/7r12h0mo' target=\"_blank\">https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab/runs/7r12h0mo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/denis-katkalo-kpi/feedback-prize-effectiveness-lab/runs/7r12h0mo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9efbf500d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cell 1: Setup and Configuration ---\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW \n",
    "from torch.cuda.amp import GradScaler, autocast # For AMP\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "PROJECT_ROOT = \"../\" \n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data/feedback-prize-effectiveness/\")\n",
    "MODELS_OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"models/\")\n",
    "OUTPUTS_DIR = os.path.join(PROJECT_ROOT, \"outputs/\") \n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TRAIN_ESSAYS_DIR = os.path.join(DATA_DIR, \"train/\")\n",
    "\n",
    "for dir_path in [MODELS_OUTPUT_DIR, OUTPUTS_DIR]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "MODEL_NAME = 'allenai/longformer-base-4096'\n",
    "MAX_LEN = 1024 \n",
    "NUM_LABELS = 3 \n",
    "N_FOLDS = 5 \n",
    "\n",
    "LEARNING_RATE = 1e-5 \n",
    "ADAM_EPSILON = 1e-8\n",
    "BATCH_SIZE = 4 \n",
    "ACCUMULATION_STEPS = 2 # For gradient accumulation\n",
    "EFFECTIVE_BATCH_SIZE = BATCH_SIZE * ACCUMULATION_STEPS\n",
    "EPOCHS = 3 \n",
    "WARMUP_STEPS_RATIO = 0.1\n",
    "RANDOM_STATE = 42\n",
    "AMP_ENABLED = True # Flag to enable/disable AMP easily\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda' and AMP_ENABLED:\n",
    "    print(\"AMP is enabled for CUDA training.\")\n",
    "elif device.type == 'cpu' and AMP_ENABLED:\n",
    "    print(\"AMP is set to enabled, but no CUDA device found. AMP will not be used.\")\n",
    "    AMP_ENABLED = False # Disable AMP if on CPU\n",
    "\n",
    "wandb.init(\n",
    "    project=\"feedback-prize-effectiveness-lab\",\n",
    "    entity=None, \n",
    "    config={\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"max_len\": MAX_LEN,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size_per_step\": BATCH_SIZE,\n",
    "        \"accumulation_steps\": ACCUMULATION_STEPS,\n",
    "        \"effective_batch_size\": EFFECTIVE_BATCH_SIZE,\n",
    "        \"epochs_per_fold\": EPOCHS,\n",
    "        \"n_folds\": N_FOLDS,\n",
    "        \"warmup_steps_ratio\": WARMUP_STEPS_RATIO,\n",
    "        \"adam_epsilon\": ADAM_EPSILON,\n",
    "        \"device\": str(device),\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"amp_enabled\": AMP_ENABLED\n",
    "    },\n",
    "    name=f\"{MODEL_NAME.split('/')[-1]}-len{MAX_LEN}-e{EPOCHS}pf-lr{LEARNING_RATE}-eff_bs{EFFECTIVE_BATCH_SIZE}-{N_FOLDS}f-{time.strftime('%Y%m%d-%H%M')}\",\n",
    "    notes=\"Training Longformer with GroupKFold, context-aware input, AMP, and Grad Accum.\",\n",
    "    dir=OUTPUTS_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9802849",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "This section involves loading the `train.csv` data and the full text of each essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f13726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Function - Load Essay Texts\n",
    "def load_essay_texts(essay_ids, essays_dir):\n",
    "    \"\"\"Loads the full text for a list of essay IDs from the specified directory.\"\"\"\n",
    "    essay_texts = {}\n",
    "    for essay_id in tqdm(essay_ids, desc=f\"Loading essays from {essays_dir}\"):\n",
    "        essay_path = os.path.join(essays_dir, f\"{essay_id}.txt\")\n",
    "        try:\n",
    "            with open(essay_path, 'r', encoding='utf-8') as f: # Added encoding\n",
    "                essay_texts[essay_id] = f.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Essay file not found {essay_path}\")\n",
    "            essay_texts[essay_id] = \"\" \n",
    "    return essay_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937778d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/feedback-prize-effectiveness/train.csv...\n",
      "Train data original shape: (36765, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading essays from ../data/feedback-prize-effectiveness/train/: 100%|██████████| 4191/4191 [00:00<00:00, 91535.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in df_train_full with empty 'discourse_text' after fillna: 0\n",
      "Number of rows in df_train_full with empty 'essay_full_text' after fillna: 0\n",
      "\n",
      "Train data shape after loading essays: (36765, 6)\n",
      "\n",
      "First 5 rows of training data:\n",
      "   discourse_id      essay_id  \\\n",
      "0  0013cc385424  007ACE74B050   \n",
      "1  9704a709b505  007ACE74B050   \n",
      "2  c22adee811b6  007ACE74B050   \n",
      "3  a10d361e54e4  007ACE74B050   \n",
      "4  db3e453ec4e2  007ACE74B050   \n",
      "\n",
      "                                      discourse_text discourse_type  \\\n",
      "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
      "1  On my perspective, I think that the face is a ...       Position   \n",
      "2  I think that the face is a natural landform be...          Claim   \n",
      "3  If life was on Mars, we would know by now. The...       Evidence   \n",
      "4  People thought that the face was formed by ali...   Counterclaim   \n",
      "\n",
      "  discourse_effectiveness                                    essay_full_text  \n",
      "0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
      "1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
      "2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
      "3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
      "4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Main Data Loading\n",
    "print(f\"Loading {TRAIN_CSV}...\")\n",
    "df_train_full = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "print(f\"Train data original shape: {df_train_full.shape}\")\n",
    "\n",
    "train_essay_ids = df_train_full['essay_id'].unique()\n",
    "train_essay_texts_map = load_essay_texts(train_essay_ids, TRAIN_ESSAYS_DIR)\n",
    "\n",
    "df_train_full['essay_full_text'] = df_train_full['essay_id'].map(train_essay_texts_map)\n",
    "\n",
    "df_train_full['discourse_text'] = df_train_full['discourse_text'].fillna('').astype(str)\n",
    "df_train_full['essay_full_text'] = df_train_full['essay_full_text'].fillna('').astype(str)\n",
    "df_train_full['discourse_type'] = df_train_full['discourse_type'].fillna('').astype(str)\n",
    "\n",
    "print(f\"\\nNumber of rows in df_train_full with empty 'discourse_text' after fillna: {df_train_full['discourse_text'].eq('').sum()}\")\n",
    "print(f\"Number of rows in df_train_full with empty 'essay_full_text' after fillna: {df_train_full['essay_full_text'].eq('').sum()}\")\n",
    "print(f\"\\nTrain data shape after loading essays: {df_train_full.shape}\")\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "print(df_train_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd791683",
   "metadata": {},
   "source": [
    "## 2. Target Encoding\n",
    "The target labels ('Ineffective', 'Adequate', 'Effective') are converted into numerical format using `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c3cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping:\n",
      "Adequate: 0\n",
      "Effective: 1\n",
      "Ineffective: 2\n",
      "Number of unique labels: 3\n",
      "\n",
      "Train DataFrame with encoded labels (first 5 rows):\n",
      "  discourse_effectiveness  effectiveness_encoded\n",
      "0                Adequate                      0\n",
      "1                Adequate                      0\n",
      "2                Adequate                      0\n",
      "3                Adequate                      0\n",
      "4                Adequate                      0\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Target Encoding ---\n",
    "label_encoder = LabelEncoder()\n",
    "df_train_full['effectiveness_encoded'] = label_encoder.fit_transform(df_train_full['discourse_effectiveness'])\n",
    "\n",
    "NUM_LABELS = len(label_encoder.classes_)\n",
    "wandb.config.update({\"num_labels\": NUM_LABELS}, allow_val_change=True)\n",
    "\n",
    "print(\"Label Encoding Mapping:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{class_name}: {i}\")\n",
    "print(f\"Number of unique labels: {NUM_LABELS}\")\n",
    "\n",
    "print(\"\\nTrain DataFrame with encoded labels (first 5 rows):\")\n",
    "print(df_train_full[['discourse_effectiveness', 'effectiveness_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b3738",
   "metadata": {},
   "source": [
    "## 3. Tokenizer and PyTorch Dataset\n",
    "\n",
    "### 3.1. Tokenizer Initialization\n",
    "We use `LongformerTokenizerFast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3776337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Tokenizer Initialization\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1c963",
   "metadata": {},
   "source": [
    "### 3.2. PyTorch Dataset Class\n",
    "A custom `Dataset` class to handle the specific input format: `[CLS] type [SEP] text [SEP] context_before [SEP] context_after [SEP]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c17f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: PyTorch Dataset Class\n",
    "class FeedbackPrizeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, essay_texts_map, has_labels=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.has_labels = has_labels\n",
    "        self.essay_texts_map = essay_texts_map \n",
    "        self.cls_token = self.tokenizer.cls_token\n",
    "        self.sep_token = self.tokenizer.sep_token\n",
    "        self.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _find_discourse_indices(self, essay_text, discourse_text):\n",
    "        try:\n",
    "            start_idx = essay_text.find(discourse_text)\n",
    "            if start_idx == -1:\n",
    "                start_idx = essay_text.find(discourse_text.strip())\n",
    "                if start_idx != -1:\n",
    "                    discourse_text = discourse_text.strip()\n",
    "            \n",
    "            if start_idx != -1:\n",
    "                end_idx = start_idx + len(discourse_text)\n",
    "                return start_idx, end_idx\n",
    "        except Exception:\n",
    "            pass\n",
    "        return -1, -1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        discourse_type_str = str(row.discourse_type).strip()\n",
    "        discourse_text_str = str(row.discourse_text).strip()\n",
    "        essay_id = row.essay_id\n",
    "        essay_full_text_str = self.essay_texts_map.get(essay_id, \"\").strip()\n",
    "\n",
    "        t_type = self.tokenizer.tokenize(discourse_type_str)\n",
    "        t_text = self.tokenizer.tokenize(discourse_text_str)\n",
    "\n",
    "        num_special_tokens = 5 # [CLS] type [SEP] text [SEP] before [SEP] after [SEP]\n",
    "\n",
    "        current_payload_len = len(t_type) + len(t_text)\n",
    "        max_payload_for_type_text = self.max_len - num_special_tokens\n",
    "\n",
    "        if current_payload_len > max_payload_for_type_text:\n",
    "            if len(t_text) > (current_payload_len - max_payload_for_type_text):\n",
    "                t_text = t_text[:len(t_text) - (current_payload_len - max_payload_for_type_text)]\n",
    "            else:\n",
    "                t_text = []\n",
    "                t_type = t_type[:max_payload_for_type_text]\n",
    "            current_payload_len = len(t_type) + len(t_text)\n",
    "        \n",
    "        t_context_before = []\n",
    "        t_context_after = []\n",
    "        remaining_budget_for_context = self.max_len - (current_payload_len + num_special_tokens)\n",
    "\n",
    "        if remaining_budget_for_context > 0 and essay_full_text_str:\n",
    "            start_idx, end_idx = self._find_discourse_indices(essay_full_text_str, discourse_text_str)\n",
    "\n",
    "            if start_idx != -1:\n",
    "                context_before_str = essay_full_text_str[:start_idx].strip()\n",
    "                context_after_str = essay_full_text_str[end_idx:].strip()\n",
    "\n",
    "                budget_for_before = remaining_budget_for_context // 2\n",
    "                budget_for_after = remaining_budget_for_context - budget_for_before\n",
    "\n",
    "                if context_before_str:\n",
    "                    temp_cb_tokens = self.tokenizer.tokenize(context_before_str)\n",
    "                    t_context_before = temp_cb_tokens[-budget_for_before:]\n",
    "                \n",
    "                if context_after_str:\n",
    "                    temp_ca_tokens = self.tokenizer.tokenize(context_after_str)\n",
    "                    t_context_after = temp_ca_tokens[:budget_for_after]\n",
    "        \n",
    "        tokens = [self.cls_token] + t_type + [self.sep_token] + t_text + \\\n",
    "                 [self.sep_token] + t_context_before + \\\n",
    "                 [self.sep_token] + t_context_after + [self.sep_token]\n",
    "        \n",
    "        if len(tokens) > self.max_len:\n",
    "            tokens = tokens[:self.max_len -1] + [self.sep_token]\n",
    "        \n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + ([self.pad_token_id] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        if self.has_labels:\n",
    "            item['labels'] = torch.tensor(row.effectiveness_encoded, dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e11a5",
   "metadata": {},
   "source": [
    "### 3.3. Example Dataset Instantiation and Item Check\n",
    "This cell demonstrates the usage of the `FeedbackPrizeDataset` and allows inspection of a sample item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a64a027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating example training dataset...\n",
      "Successfully created example dataset with 5 samples.\n",
      "\n",
      "Sample item from dataset (index 0):\n",
      "  input_ids: shape torch.Size([1024]), dtype torch.int64\n",
      "  attention_mask: shape torch.Size([1024]), dtype torch.int64\n",
      "  labels: shape torch.Size([]), dtype torch.int64\n",
      "\n",
      "  Decoded input_ids (first 100 tokens, index 0):\n",
      "  '<s>Lead</s>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform.</s></s>On my perspective, I think that the face is a natural landform because I'\n",
      "  Padding token ID (1) found, indicating padding is applied.\n",
      "  Number of attention tokens (1s in mask): 440\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Dataset Instantiation and Check\n",
    "print(\"Instantiating example training dataset...\")\n",
    "\n",
    "example_check_df = df_train_full.head() \n",
    "temp_dataset = FeedbackPrizeDataset(example_check_df, tokenizer, MAX_LEN, train_essay_texts_map, has_labels=True)\n",
    "\n",
    "if len(temp_dataset) > 0:\n",
    "    print(f\"Successfully created example dataset with {len(temp_dataset)} samples.\")\n",
    "    sample_item = temp_dataset[0]\n",
    "    print(\"\\nSample item from dataset (index 0):\")\n",
    "    for key, value in sample_item.items():\n",
    "        print(f\"  {key}: shape {value.shape}, dtype {value.dtype}\")\n",
    "    \n",
    "    decoded_text = tokenizer.decode(sample_item['input_ids'][:100], skip_special_tokens=False)\n",
    "    print(f\"\\n  Decoded input_ids (first 100 tokens, index 0):\\n  '{decoded_text}'\")\n",
    "    \n",
    "    if sample_item['input_ids'].tolist().count(tokenizer.pad_token_id) > 0:\n",
    "        print(f\"  Padding token ID ({tokenizer.pad_token_id}) found, indicating padding is applied.\")\n",
    "    print(f\"  Number of attention tokens (1s in mask): {sample_item['attention_mask'].sum().item()}\")\n",
    "else:\n",
    "    print(\"Example dataset is empty or not run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bdb2f",
   "metadata": {},
   "source": [
    "## 4. GroupKFold Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "groupkfold_setup_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold initialized with 5 folds.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: GroupKFold Setup\n",
    "gkf = GroupKFold(n_splits=N_FOLDS)\n",
    "groups = df_train_full['essay_id']\n",
    "X = df_train_full \n",
    "y = df_train_full['effectiveness_encoded']\n",
    "\n",
    "print(f\"GroupKFold initialized with {N_FOLDS} folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8628f",
   "metadata": {},
   "source": [
    "## 5. Training and Evaluation Loop with GroupKFold\n",
    "The main loop iterates for `N_FOLDS`. In each fold:\n",
    "1.  The model, optimizer, and scheduler are re-initialized.\n",
    "2.  Data is split into training and validation sets for the current fold.\n",
    "3.  DataLoaders are created.\n",
    "4.  The model is trained and evaluated for `EPOCHS` using AMP and gradient accumulation.\n",
    "5.  Metrics are calculated and recorded for the fold.\n",
    "6.  The best model for the fold is saved using `save_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0decc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FOLD 1 / 5 ==========\n",
      "  Training set size for fold 1: 29412\n",
      "  Validation set size for fold 1: 7353\n",
      "  Initializing model for fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_242375/4226481972.py:40: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(AMP_ENABLED and device.type == 'cuda'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ---- Epoch 1 / 3 for Fold 1 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1 Training:   0%|          | 0/7353 [00:00<?, ?it/s]/tmp/ipykernel_242375/4226481972.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(AMP_ENABLED and device.type == 'cuda')):\n",
      "Initializing global attention on CLS token...\n",
      "Fold 1 Epoch 1 Training:  11%|█         | 820/7353 [04:30<35:52,  3.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m total_train_loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# Accumulate scaled/normalized loss\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m AMP_ENABLED \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f9fbba82440>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f9efc0fe290, execution_count=9 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f9efc0fe2c0, raw_cell=\"# --- Cell 9: Training and Evaluation Loop with Gr..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/denis/kpi/iasa_nlp_labs/feedback_prize_effectiveness/notebooks/training_v2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:769\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kpi/iasa_nlp_labs/feedback_prize_effectiveness/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# --- Cell 9: Training and Evaluation Loop with GroupKFold, AMP, and Gradient Accumulation ---\n",
    "def format_time(elapsed_seconds):\n",
    "    elapsed_rounded = int(round(elapsed_seconds))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "all_fold_val_logloss = []\n",
    "all_fold_val_accuracy = []\n",
    "\n",
    "for fold_num, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "    print(f\"\\n========== FOLD {fold_num + 1} / {N_FOLDS} ==========\")\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    df_train_fold = df_train_full.iloc[train_idx]\n",
    "    df_val_fold = df_train_full.iloc[val_idx]\n",
    "\n",
    "    print(f\"  Training set size for fold {fold_num+1}: {len(df_train_fold)}\")\n",
    "    print(f\"  Validation set size for fold {fold_num+1}: {len(df_val_fold)}\")\n",
    "\n",
    "    train_torch_dataset_fold = FeedbackPrizeDataset(df_train_fold, tokenizer, MAX_LEN, train_essay_texts_map, has_labels=True)\n",
    "    val_torch_dataset_fold = FeedbackPrizeDataset(df_val_fold, tokenizer, MAX_LEN, train_essay_texts_map, has_labels=True)\n",
    "\n",
    "    try:\n",
    "        num_avail_workers = len(os.sched_getaffinity(0)) // 2\n",
    "    except AttributeError:\n",
    "        num_avail_workers = (os.cpu_count() // 2) if os.cpu_count() and os.cpu_count() > 1 else 0\n",
    "    num_avail_workers = max(0, num_avail_workers) \n",
    "\n",
    "    train_dataloader_fold = DataLoader(train_torch_dataset_fold, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_avail_workers, pin_memory=True if device.type == 'cuda' else False)\n",
    "    val_dataloader_fold = DataLoader(val_torch_dataset_fold, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=num_avail_workers, pin_memory=True if device.type == 'cuda' else False)\n",
    "\n",
    "    print(f\"  Initializing model for fold {fold_num+1}...\")\n",
    "    model = LongformerForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=ADAM_EPSILON)\n",
    "    total_steps_fold = math.ceil(len(train_dataloader_fold) / ACCUMULATION_STEPS) * EPOCHS\n",
    "    num_warmup_steps_fold = math.ceil(total_steps_fold * WARMUP_STEPS_RATIO)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps_fold, num_training_steps=total_steps_fold)\n",
    "    \n",
    "    scaler = GradScaler(enabled=(AMP_ENABLED and device.type == 'cuda'))\n",
    "\n",
    "    best_val_logloss_fold = float('inf')\n",
    "    fold_training_stats = []\n",
    "\n",
    "    for epoch_i in range(EPOCHS):\n",
    "        print(f\"    ---- Epoch {epoch_i + 1} / {EPOCHS} for Fold {fold_num + 1} ----\")\n",
    "        \n",
    "        model.train()\n",
    "        total_train_loss_epoch = 0\n",
    "        optimizer.zero_grad() # Zero gradients at the beginning of each epoch\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader_fold, desc=f\"Fold {fold_num+1} Epoch {epoch_i+1} Training\")):\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            b_attention_mask = batch['attention_mask'].to(device)\n",
    "            b_labels = batch['labels'].to(device)\n",
    "\n",
    "            with autocast(enabled=(AMP_ENABLED and device.type == 'cuda')):\n",
    "                outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
    "                loss = outputs.loss\n",
    "                if ACCUMULATION_STEPS > 1:\n",
    "                    loss = loss / ACCUMULATION_STEPS\n",
    "            \n",
    "            total_train_loss_epoch += loss.item() # Accumulate scaled/normalized loss\n",
    "            \n",
    "            if AMP_ENABLED and device.type == 'cuda':\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            if (step + 1) % ACCUMULATION_STEPS == 0 or (step + 1) == len(train_dataloader_fold):\n",
    "                if AMP_ENABLED and device.type == 'cuda':\n",
    "                    scaler.unscale_(optimizer) # Unscale before clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                if AMP_ENABLED and device.type == 'cuda':\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss_epoch = total_train_loss_epoch / (math.ceil(len(train_dataloader_fold) / ACCUMULATION_STEPS) if ACCUMULATION_STEPS > 0 else len(train_dataloader_fold))\n",
    "        print(f\"      Average training loss for epoch: {avg_train_loss_epoch:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        total_eval_loss_epoch = 0\n",
    "        all_val_preds_probs_epoch = []\n",
    "        all_val_labels_epoch = []\n",
    "        for batch in tqdm(val_dataloader_fold, desc=f\"Fold {fold_num+1} Epoch {epoch_i+1} Validation\"):\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            b_attention_mask = batch['attention_mask'].to(device)\n",
    "            b_labels = batch['labels'].to(device)\n",
    "            with torch.no_grad():\n",
    "                with autocast(enabled=(AMP_ENABLED and device.type == 'cuda')):\n",
    "                    outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "            total_eval_loss_epoch += loss.item()\n",
    "            probs = torch.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "            all_val_preds_probs_epoch.extend(probs)\n",
    "            all_val_labels_epoch.extend(b_labels.to('cpu').numpy())\n",
    "        \n",
    "        avg_val_CE_loss_epoch = total_eval_loss_epoch / len(val_dataloader_fold)\n",
    "        all_val_labels_flat_epoch = np.array(all_val_labels_epoch)\n",
    "        all_val_preds_probs_stacked_epoch = np.vstack(all_val_preds_probs_epoch)\n",
    "        all_val_preds_classes_epoch = np.argmax(all_val_preds_probs_stacked_epoch, axis=1)\n",
    "        val_accuracy_epoch = accuracy_score(all_val_labels_flat_epoch, all_val_preds_classes_epoch)\n",
    "        val_logloss_metric_epoch = log_loss(all_val_labels_flat_epoch, all_val_preds_probs_stacked_epoch, labels=label_encoder.transform(label_encoder.classes_))\n",
    "        \n",
    "        print(f\"      Validation LogLoss: {val_logloss_metric_epoch:.4f}, Accuracy: {val_accuracy_epoch:.4f}\")\n",
    "        wandb.log({\n",
    "            f\"fold_{fold_num+1}_epoch\": epoch_i + 1,\n",
    "            f\"fold_{fold_num+1}_train_loss\": avg_train_loss_epoch,\n",
    "            f\"fold_{fold_num+1}_val_CE_loss\": avg_val_CE_loss_epoch,\n",
    "            f\"fold_{fold_num+1}_val_logloss\": val_logloss_metric_epoch,\n",
    "            f\"fold_{fold_num+1}_val_accuracy\": val_accuracy_epoch,\n",
    "            f\"fold_{fold_num+1}_learning_rate\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "        fold_training_stats.append({\n",
    "            'fold': fold_num + 1,\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss_epoch,\n",
    "            'Valid. LogLoss': val_logloss_metric_epoch,\n",
    "            'Valid. Accur.': val_accuracy_epoch\n",
    "        })\n",
    "\n",
    "        if val_logloss_metric_epoch < best_val_logloss_fold:\n",
    "            best_val_logloss_fold = val_logloss_metric_epoch\n",
    "            save_directory = os.path.join(MODELS_OUTPUT_DIR, f\"{wandb.config.model_name.split('/')[-1]}-fold-{fold_num}-best\")\n",
    "            if not os.path.exists(save_directory):\n",
    "                os.makedirs(save_directory)\n",
    "            model.save_pretrained(save_directory)\n",
    "            tokenizer.save_pretrained(save_directory)\n",
    "            print(f\"      Best val_logloss for fold {fold_num+1} improved to {best_val_logloss_fold:.4f}. Saving model and tokenizer to {save_directory}\")\n",
    "    \n",
    "    all_fold_val_logloss.append(best_val_logloss_fold)\n",
    "    best_epoch_stats_for_fold = next((stat for stat in fold_training_stats if stat['fold'] == fold_num + 1 and abs(stat['Valid. LogLoss'] - best_val_logloss_fold) < 1e-5), None)\n",
    "    if best_epoch_stats_for_fold:\n",
    "        all_fold_val_accuracy.append(best_epoch_stats_for_fold['Valid. Accur.'])\n",
    "    else: \n",
    "        all_fold_val_accuracy.append(fold_training_stats[-1]['Valid. Accur.'] if fold_training_stats else 0)\n",
    "\n",
    "    print(f\"  Fold {fold_num + 1} completed. Best Val LogLoss: {best_val_logloss_fold:.4f}\")\n",
    "    print(f\"  Fold {fold_num + 1} took: {format_time(time.time() - fold_start_time)}\")\n",
    "    \n",
    "    del model, optimizer, scheduler, train_dataloader_fold, val_dataloader_fold, train_torch_dataset_fold, val_torch_dataset_fold, scaler\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n======== K-Fold Training complete! ========\\n\")\n",
    "avg_all_folds_logloss = np.mean(all_fold_val_logloss)\n",
    "std_all_folds_logloss = np.std(all_fold_val_logloss)\n",
    "avg_all_folds_accuracy = np.mean(all_fold_val_accuracy)\n",
    "std_all_folds_accuracy = np.std(all_fold_val_accuracy)\n",
    "\n",
    "print(f\"Average Validation LogLoss across {N_FOLDS} folds: {avg_all_folds_logloss:.4f} +/- {std_all_folds_logloss:.4f}\")\n",
    "print(f\"Average Validation Accuracy across {N_FOLDS} folds: {avg_all_folds_accuracy:.4f} +/- {std_all_folds_accuracy:.4f}\")\n",
    "\n",
    "wandb.summary[\"avg_cv_val_logloss\"] = avg_all_folds_logloss\n",
    "wandb.summary[\"std_cv_val_logloss\"] = std_all_folds_logloss\n",
    "wandb.summary[\"avg_cv_val_accuracy\"] = avg_all_folds_accuracy\n",
    "wandb.summary[\"std_cv_val_accuracy\"] = std_all_folds_accuracy\n",
    "\n",
    "if fold_training_stats:\n",
    "    df_last_fold_stats = pd.DataFrame([s for s in fold_training_stats if s['fold'] == N_FOLDS])\n",
    "    if not df_last_fold_stats.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(df_last_fold_stats['epoch'], df_last_fold_stats['Training Loss'], label='Training Loss (Last Fold)')\n",
    "        plt.plot(df_last_fold_stats['epoch'], df_last_fold_stats['Valid. LogLoss'], label='Validation LogLoss (Last Fold)')\n",
    "        plt.title(f'Loss over Epochs (Fold {N_FOLDS})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(df_last_fold_stats['epoch'], df_last_fold_stats['Valid. Accur.'], label='Validation Accuracy (Last Fold)')\n",
    "        plt.title(f'Accuracy over Epochs (Fold {N_FOLDS})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(OUTPUTS_DIR, f\"training_curves_fold_{N_FOLDS}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Training curves plot for last fold saved to {plot_path}\")\n",
    "        plt.show()\n",
    "        wandb.log({\"last_fold_training_curves\": wandb.Image(plot_path)})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656040a",
   "metadata": {},
   "source": [
    "## 6. Next Steps & Conclusions from K-Fold Training\n",
    "- **Analyze Fold Performance**: Review the performance metrics (LogLoss, Accuracy) for each fold. Identify if any fold performed significantly differently.\n",
    "- **Error Analysis**: On the OOF (out-of-fold) predictions, analyze common errors or types of discourse where the model struggles.\n",
    "- **Hyperparameter Tuning**: Based on K-Fold results, further tune hyperparameters like learning rate, batch size, or number of epochs.\n",
    "- **Ensembling (Optional)**: If models from each fold are saved, their predictions can be ensembled for a potentially more robust submission.\n",
    "- **Final Model Training**: After identifying optimal hyperparameters, a final model can be trained on the entire training dataset (or a larger portion) for the specified number of epochs.\n",
    "- **Prediction on Test Set**: Use the best single fold model, an ensemble, or the final model trained on all data to generate predictions for the actual test set (done in `prediction_and_submission.ipynb`).\n",
    "\n",
    "The K-Fold cross-validation provides a more reliable estimate of the model's generalization performance compared to a single train-validation split. The average LogLoss and Accuracy across folds are key indicators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
